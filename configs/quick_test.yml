# Quick test configuration for development and debugging

# Model Architecture - minimal for fast testing
model:
  state_dim: 4  # Will be overridden dynamically based on the data
  n_experts: 4  # More experts for better coverage
  expert_architecture:
    depth: 5  # Shallower but wider
    width: 128  # Wider for more capacity
    activation: "tanh"  # Better for continuous dynamics
    residual: true
    dropout: 0.0
  gating_architecture:
    depth: 3  # Deeper gating for better routing
    width: 32  # Wider gating
    activation: "relu"
  history_embedding:
    type: "lstm"
    hidden_dim: 32  # Larger history
    num_layers: 1
  temperature: 0.7  # Balanced temperature
  expert_threshold: 0.01
  # Initialization settings
  use_improved_init: true
  expert_init_strategy: "mixed"  # Better for diverse experts
  gating_init_strategy: "uniform"  # Start with uniform routing

# Training Configuration - minimal epochs
training:
  batch_size: 256  # Larger batch for stability
  learning_rate: 3e-4  # Optimal learning rate
  num_epochs: 200  # Very short
  early_stopping_patience: 35
  gradient_clip_norm: 5.0  # Less restrictive clipping
  sequence_length: 50
  optimizer: "adam"
  scheduler:
    type: "cosine"
    warmup_epochs: 10  # Longer warmup
    min_lr: 1e-6
  regularization:
    route_weight: 0.0        # No routing penalty initially
    expert_weight: 1e-6      # Very light L2 regularization
    diversity_weight: 0.0    # No diversity penalty - let experts specialize
    smoothness_weight: 0.0  # No smoothness penalty
    balance_weight: 0.0      # No balance penalty - natural specialization

# Integration Configuration - fast settings
integration:
  method: "dopri5"
  rtol: 1e-3
  atol: 1e-4
  max_step_size: 0.1
  min_step_size: 1e-4
  adaptive_step: false  # Fixed step for speed
  routing_aware_step: false
  # Stability control
  dynamics_max_norm: 50.0  # No dynamics bounding for AME-ODE

# Data Configuration - small dataset
data:
  synthetic_systems:
    - name: "multi_scale_oscillators"
      enabled: true
      n_trajectories: 2000  # More data
      trajectory_length: 100  # Longer trajectories
      sampling_dt: 0.01  # Finer sampling
      params:
        freq_fast: 10.0
        freq_slow: 0.1
        coupling_strength: [0.1, 0.1]  # Stronger coupling
  noise:
    observation_noise: 0.01
    process_noise: 0.0
  train_val_test_split: [0.6, 0.2, 0.2]
  temporal_sampling: "uniform"
  augmentation:
    random_rotation: false
    random_scaling: false

# Computational Resources
compute:
  device: "cuda"
  mixed_precision: false
  gradient_checkpointing: false
  multi_gpu: false
  num_workers: 2

# Logging - frequent for debugging
logging:
  log_dir: "./logs_test"
  checkpoint_dir: "./checkpoints_test"
  tensorboard: true
  wandb:
    enabled: false
  save_frequency: 5
  log_frequency: 10

# Evaluation - minimal metrics
evaluation:
  metrics:
    - "trajectory_mse"
    - "computational_efficiency"
  visualization:
    phase_portraits: true
    routing_heatmaps: false
    trajectory_decomposition: false